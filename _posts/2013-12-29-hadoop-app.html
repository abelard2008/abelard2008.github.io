---
category: computer science and enginneering
layout: post
title: "How to build a Application with Hadoop"
tags: ["Big data", "Hadoop", Eclipse]
---

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">使用eclipse编写hadoop应用程序</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>下载<a href="http://code.google.com/p/hadoop-eclipse-plugin/downloads/list">eclipse plugin for hadoop</a> 名称为hadoop-0.20.3-dev-eclipse-plugin.jar
放到，eclipse的 eclipse/plugins/目录下，重启eclipse后，在
file-&gt;new-&gt;project里，就可以看到map/reduce project
</li>

<li>打开 Window-&gt;Preferences,找到 Hadoop Map/Reduce,设置Hadoop
Installation Directory 为eclipse的主目录如：
/home/abelard/hadoop-0.20.203.0
</li>
</ul>

<div class="photofloatr">
  <p><img src="/images/hadoop-preferences.png" width="500"
    height="350" alt="hadoop-preferences.png"></p>
  <p>设置Preferences for hadoop</p>
</div>

<ul class="org-ul">
<li>为了运行hadoop 的 map/reduce 程序，需要先运行hadoop，然后设置
Hadoop Locations, 打开 Window-&gt;Show View -&gt; others，找到
Map/Reduce locations
</li>
</ul>
<div class="photofloatr">
  <p><img src="/images/Hadoop-locations.png" width="500"
    height="350" alt="Hadoop-locations.png"></p>
  <p>Hadoop locations</p>
</div>

<p>
点击图 <i>hadoop locations</i> 右上角的 Edit Hadoop location 或 New Hadoop
location 则打开
</p>

<div class="photofloatr">
  <p><img src="/images/edit-hadoop-location.png" width="500"
    height="350" alt="edit-hadoop-location.png"></p>
  <p>edit hadoop location</p>
</div>

<p>
在图 <i>edit hadoop location</i> 注意 左边的map/reduce端口来自
mapred-site.xml，右边的hdfs端口来自core-site.xml
</p>

<ul class="org-ul">
<li>创建map/reduce工程，运行时，点击 Run as -&gt; Run on Hadoop,就可以了
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">如何开始hadoop的运行</h2>
<div class="outline-text-2" id="text-2">
<ul class="org-ul">
<li>准备工作：如果要使用真实的分布式，首先将master节点设置成
DNS服务器，并将其起动。<a href="file://study/doctor/note/org/linux-system-management.html">DNS服务器设置</a>
</li>
<li>解压hadoop压缩文件hadoop-0.20.203.0rc1.tar.gz
</li>
<li>进入hadoop主目录，修改conf目录下的配置文件：
</li>
</ul>
<p>
hadoop-env.sh
</p>
<pre class="example">
export JAVA_HOME=/software/spring-mvc/jdk1.7.0_01/
</pre>
<p>
core-site.xml
</p>
<pre class="example">
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://dillon.cloud:9005&lt;/value&gt;
  &lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/home/abelard/hadoop-tmp&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;
</pre>

<p>
mapred-site.xml
</p>
<pre class="example">
&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;mapred.job.tracker&lt;/name&gt;
         &lt;value&gt;dillon.cloud:9001&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</pre>

<p>
hdfs-site.xml
</p>
<pre class="example">
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.name.dir&lt;/name&gt;
    &lt;value&gt;/home/abelard/namenode&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.data.dir&lt;/name&gt;
    &lt;value&gt;/home/abelard/datanode&lt;/value&gt;
  &lt;/property&gt;

&lt;/configuration&gt;
</pre>
<ul class="org-ul">
<li>配置 SSH 的无密码公钥认证
如果要使用真实的分布式系统，需要将所有master和slave节点，
都设成无密码公钥认证，并且将自己的认证文件authorized_keys
文件，添加到所有节点(包括自己)的authorized_keys中。
<ul class="org-ul">
<li>单个节点自己的配置操作过程  参考：<a href="file://study/doctor/note/org/linux-system-management.html">linux系统管理</a>
</li>
<li>远程节点无密登录的设置：将自己的认证文件authorized_keys，
     添加到远程节点的authorized_keys.
</li>
</ul>
</li>
<li>运行命令序列
</li>
</ul>
<pre class="example">
[abelard@dillon hadoop-0.20.203.0]$ bin/hadoop namenode -format
[abelard@dillon hadoop-0.20.203.0]$ bin/start-all.sh 
starting namenode, logging to /home/abelard/hadoop-0.20.203.0/bin/../logs/hadoop-abelard-namenode-abelard.localdomain.out
10.13.32.243: starting datanode, logging to /home/abelard/hadoop-0.20.203.0/bin/../logs/hadoop-abelard-datanode-abelard.localdomain.out
abelard.localdomain: starting secondarynamenode, logging to /home/abelard/hadoop-0.20.203.0/bin/../logs/hadoop-abelard-secondarynamenode-abelard.localdomain.out
starting jobtracker, logging to /home/abelard/hadoop-0.20.203.0/bin/../logs/hadoop-abelard-jobtracker-abelard.localdomain.out
10.13.32.243: starting tasktracker, logging to /home/abelard/hadoop-0.20.203.0/bin/../logs/hadoop-abelard-tasktracker-abelard.localdomain.out
[abelard@dillon hadoop-0.20.203.0]$ bin/stop-all.sh 
stopping jobtracker
10.13.32.243: stopping tasktracker
stopping namenode
10.13.32.243: stopping datanode
abelard.localdomain: stopping secondarynamenode
//通过start-all.sh和stop-all.sh的结果消息，可以看出，启动是
否正常，依据不正常的消息，去查看log目录下的具体信息来解决。
[abelard@dillon hadoop-0.20.203.0]$ bin/hadoop fs -ls //使用
hdfs文件系统命令
[abelard@dillon hadoop-0.20.203.0]$ bin/hadoop fs -put
./conf/*.xml input
[abelard@dillon hadoop-0.20.203.0]$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'
</pre>


<ul class="org-ul">
<li>查看运行结果
</li>
</ul>
<p>
在浏览器中输入：
</p>
<pre class="example">
http://192.168.0.88:50030  //mapreduce work
http://192.168.0.88:50070  //hdfs
</pre>
<p>
有任何错误看logs目录下的:
hadoop-abelard-namenode-dillon.cloud.log
hadoop-abelard-datanode-dillon.cloud.log
</p>

<ul class="org-ul">
<li>测试例子命令序列
</li>
</ul>
<pre class="example">
bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'
</pre>
<p>
常见异常：
如hadoop-abelard-datanode-abelard.localdomain.log中的
2013-01-30 20:44:08,779 ERROR
org.apache.hadoop.hdfs.server.datanode.DataNode:
java.io.IOException: Incompatible namespaceIDs in
/home/abelard/datanode: namenode namespaceID = 1811935815;
datanode namespaceID = 1837173423
这种不兼容的问题，是hdfs的格式化一个已有的文件系统造成的，将
前面core-site.xml和hdfs-site.xml所配置的目录为：datanode和
namenode全部删除后，重新格式化即可。
</p>
<pre class="example">
[abelard@dillon hadoop-0.20.203.0]$ bin/hadoop namenode -format
</pre>
<p>
所创键的目录全部删除，重新创建，根据
</p>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">MapReduce概念</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li>MapReduce是一个对大规模数据进行分布式计算的编程模型，并且是一个在由
商业服务器构成的集群上进行大规模数据处理的执行框架。它是按照几十年
来，在并行和分布式处理中的著名原理来构建的。
</li>
</ul>
</div>
</div>
<div id="outline-container-sec-4" class="outline-2">
<h2 id="sec-4">Hadoop中的技术</h2>
<div class="outline-text-2" id="text-4">
<ul class="org-ul">
<li>不一样的代码片段
</li>
</ul>

<pre class="example">
//org.apache.hadoop.mapred.MapTask
Class&lt;? extends CompressionCodec&gt; codecClass = null;
    if (conf.getCompressMapOutput()) {
        codecClass = conf.getMapOutputCompressorClass(DefaultCodec.class);
}
</pre>
<p>
这样定义变量想让codecClass可以赋值为CompressionCodec的子类实例。
</p>
</div>
</div>

<div id="outline-container-sec-5" class="outline-2">
<h2 id="sec-5">Hadoop中的进程启动</h2>
<div class="outline-text-2" id="text-5">
<p>
在执行start-all.sh时，启动了几个独立的进程，他们是：
</p>
<ul class="org-ul">
<li>org.apache.hadoop.hdfs.server.namenode.NameNode 
</li>
<li>org.apache.hadoop.hdfs.server.datanode.DataNode
</li>
<li>org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
</li>
<li>org.apache.hadoop.mapred.JobTracker
</li>
<li>dillon.cloud: org.apache.hadoop.mapred.TaskTracker
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-6" class="outline-2">
<h2 id="sec-6">最近主要看了哪些文章，有什么收获</h2>
<div class="outline-text-2" id="text-6">
<ul class="org-ul">
<li>hadoop definitive guide 从实践的角度，讨论怎么使用hadoop来进行大规模
数据分析；hadoop实现的 streaming I/O，让用户可以通过不同的编程语言实
现map和reduce功能，如附录C使用shell；书中详细讨论了各种参数的使用情
景。
</li>
<li>Data-Intensive Text Processing with MapReduce 介绍hadoop中的
MapReduce结构如何实现，比较系统和深入。采用模式的方式讨论MapReduce的
使用场景，非常值得研究，因此对其中的很多模式，在
<a href="http://lintool.github.com/Cloud9/">http://lintool.github.com/Cloud9/</a> 中设计的相应的例子，以供学习。
</li>

<li>berley的HOP，为了hadoop的MapReduce能适应于real-time的大规模数据分析，修
改了hadoop，主要亮点是将hadoop原来的pull方式改为push方式，来将mapper结
果传递到reducer中；另外，使用了pipeline技术。
</li>

<li>google的percolator，为解决大规模数据集的实时部分更新，提出用基于增量
处理来代替基于批量的索引。
</li>

<li>经典的流处理引擎之一Borealis，是一个分布式的流处理引擎，在Aurora的基
础上构建，主要解决动态更新查询结果和修改查询条件。
</li>

<li>Continuous Analytics, online aggregation,都是实时mapreduce的例子，所
采用的方法(1)修改hadoop (2) 在新设计的mapreduce平台Hyracks上实现。
</li>

<li>Hyracks是一个新的mapreduce平台，为了解决hadoop中很多的不足，它采用了
在1990年WISC的GAMMA并行数据库的思想，加上1997年发表的操作树模型来进
行block依赖的管理。另外在架构上使用cluster controller 和 node
controller的方式，使用Overlog来实现Cluster controller的处理逻辑。
</li>
</ul>
</div>
</div>
