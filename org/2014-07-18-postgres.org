#+STARTUP: showall indent
#+STARTUP: hidestars
#+OPTIONS:   H:2 num:nil toc:nil \n:nil ::t |:t -:t f:t *:t <:t

#+OPTIONS:   tex:t  d:nil todo:t pri:nil tags:not-in-toc
#+BEGIN_HTML
---
category: computer science and enginneering
layout: post
title: "Postgres Source Code and Theory"
description: "study database through postgres"
tags: ["database",tools]
---
{% include JB/setup %}

#+END_HTML

* Replacement Selection
ExecSort() extract all tuples 

#+BEGIN_SRC c
for (;;)
{
	slot = ExecProcNode(outerNode);

	if (TupIsNull(slot))
		break;

	tuplesort_puttupleslot(tuplesortstate, slot);
}
#+END_SRC

tuplesort_puttupleslot() -> ... -> puttuple_common(), at this time,
the state->status is TSS_INITIAL, when state->memtupcount is less than
state->memtupsize, where memtupsize is 8192 (equal to BLCKSZ).
#+BEGIN_SRC c
state->memtuples[state->memtupcount++] = *tuple;
#+END_SRC

when memtupcount is larger than 8192, inittapes() will be called and
use dumptuples() to insert state->memtuples[0] into relative temp
files (called run), and the new tuple from ExecProcNode(outerNode)
will insert state->memtuples.

* planner
select * from customer:
planner()<-pg_plan_query()<-pg_plan_queries()<-exec_simple_query()

explain select * from customer: planner()<-pg_plan_query()<-ExplainOneQuery()<-ExplainQuery()

* sql
** generate random number
#+BEGIN_SRC sql
tuplesort=# select random();
      random       
-------------------
 0.862202602438629
(1 row)
#+END_SRC

** create function for arbitrary date in a specified rang
#+BEGIN_SRC sql
tuplesort=# create or replace function generate_dates(
dt1 date,
dt2 date,
n int) returns setof date as 
$$
select $1 + $3;
$$ language 'sql' immutable;

tuplesort=# select generate_dates('2009-01-01','2009-12-31',mod((random()*10000)::integer,365));
 generate_dates 
----------------
 2009-11-13
(1 row)

tuplesort=# select generate_dates('2009-01-01','2009-12-31',mod((random()*10000)::integer,365));
 generate_dates 
----------------
 2009-09-28
(1 row)

#+END_SRC

* parser
the parser include two phases: parser and transfromation.

the parser phase mainly creates a specified called raw
parse tree,  which is a linked list of parse nodes. there are
several kinds of nodes, as defined in parsenodes.h, such as SelectStmt,
#+BEGIN_SRC c
typedef struct SelectStmt
{
	NodeTag		type;

	/*
	 * These fields are used only in "leaf" SelectStmts.
	 */
	List	   *distinctClause; /* NULL, list of DISTINCT ON exprs, or
								 * lcons(NIL,NIL) for all (SELECT DISTINCT) */
	IntoClause *intoClause;		/* target for SELECT INTO / CREATE TABLE AS */
	List	   *targetList;		/* the target list (of ResTarget) */
	List	   *fromClause;		/* the FROM clause */
	Node	   *whereClause;	/* WHERE qualification */
	List	   *groupClause;	/* GROUP BY clauses */
	Node	   *havingClause;	/* HAVING conditional-expression */
	List	   *windowClause;	/* WINDOW window_name AS (...), ... */
	WithClause *withClause;		/* WITH clause */
      ...
}
#+END_SRC
the first member of these classes of structures all is NodeTag, every
query will create a node with some fixed members, in above
SelectStmt, which has intClause, targetList, etc,. so in gram.y, for
every kind of query, it creates a root node for special query:
#+BEGIN_SRC c
simple_select:
			SELECT opt_distinct target_list
			into_clause from_clause where_clause
			group_clause having_clause window_clause
				{
					SelectStmt *n = makeNode(SelectStmt);
					n->distinctClause = $2;
					n->targetList = $3;
					n->intoClause = $4;
					n->fromClause = $5;
...
#+END_SRC 
and the definition for makeNode in nodes.h
#+BEGIN_SRC c
extern PGDLLIMPORT Node *newNodeMacroHolder;
#define newNode(size, tag) \
( \
	AssertMacro((size) >= sizeof(Node)),		/* need the tag, at least */ \
	newNodeMacroHolder = (Node *) palloc0fast(size), \
	newNodeMacroHolder->type = (tag), \
	newNodeMacroHolder \
)
#endif   /* __GNUC__ */


#define makeNode(_type_)		((_type_ *) newNode(sizeof(_type_),T_##_type_))

#+END_SRC
T_##_type_ should be paid attention, because it will be assigned
to the first member of the root node, such as SelectStmt.type, after
that, many task will be completed by the type.  

in analysis phase, the previous raw parse tree will be sematic
analysis.
#+BEGIN_SRC c
pg_analyze_and_rewrite(Node *parsetree, const char *query_string,...) 
-> parse_analyze(parsetree, query_string, paramTypes, numParams)
-> query = transformStmt(pstate, parseTree);
-> transformSelectStmt(ParseState *pstate, SelectStmt *stmt)
#+END_SRC

after parse_analyze(), we will get a query (type: Query)

in transformStmt():

#+BEGIN_SRC c
Query *
transformStmt(ParseState *pstate, Node *parseTree)
{
	Query	   *result;

	switch (nodeTag(parseTree))
	{
		case T_SelectStmt:
			{
				SelectStmt *n = (SelectStmt *) parseTree;

				if (n->valuesLists)
					result = transformValuesClause(pstate, n);
				else if (n->op == SETOP_NONE)
					result = transformSelectStmt(pstate, n);
				else
					result = transformSetOperationStmt(pstate, n);
			}
			break;

#+END_SRC

in transformSelectStmt():
#+BEGIN_SRC c
static Query *
transformSelectStmt(ParseState *pstate, SelectStmt *stmt)
{
	Query	   *qry = makeNode(Query);

#+END_SRC
from the first statement, the node type was transformed from
SelectStmt to Query.

* system catalog


** pg_opclass

| Column       | Type    | Modifiers |
|--------------+---------+-----------|
| opcmethod    | oid     | not null  |
| opcname      | name    | not null  |
| opcnamespace | oid     | not null  |
| opcowner     | oid     | not null  |
| opcfamily    | oid     | not null  |
| opcintype    | oid     | not null  |
| opcdefault   | boolean | not null  |
| opckeytype   | oid     | not null  |

** pg_am

| Column       | Type     | Modifiers |
|--------------+----------+-----------|
| amname       | name     | not null  |
| amstrategies | smallint | not null  |
| amsupport    | smallint | not null  |

** pg_amop

| Column        | Type     | Modifiers |
|---------------+----------+-----------|
| amopfamily    | oid      | not null  |
| amoplefttype  | oid      | not null  |
| amoprighttype | oid      | not null  |
| amopstrategy  | smallint | not null  |
| amopopr       | oid      | not null  |
| amopmethod    | oid      | not null  | 

*** pg_opfamily

| Column       | Type | Modifiers |
|--------------+------+-----------|
| opfmethod    | oid  | not null  |
| opfname      | name | not null  |
| opfnamespace | oid  | not null  |
| opfowner     | oid  | not null  |

NOTE: opcmethod, amopmethod and opfmethod are the same value as
pg_am's oid, so that the following query is right:

#+BEGIN_SRC sql
SELECT am.amname AS index_method,
       opc.opcname AS opclass_name
    FROM pg_am am, pg_opclass opc
    WHERE opc.opcmethod = am.oid
    ORDER BY index_method, opclass_name;

SELECT am.amname AS index_method,
       opf.opfname AS opfamily_name,
       amop.amopopr::regoperator AS opfamily_operator
    FROM pg_am am, pg_opfamily opf, pg_amop amop
    WHERE opf.opfmethod = am.oid AND
          amop.amopfamily = opf.oid
    ORDER BY index_method, opfamily_name, opfamily_operator;
#+END_SRC

also, amopfamily in pg_amop is the same value as pg_opfamily's oid.

* operator classes explained[fn:1]

** what is an operator class?
in PostgreSQL an index is not a hardwired thing,capable of following
just one strategy.

Asume that two values stored in a database:

#+BEGIN_SRC sql
CREATE TABLE t_sva (sva text);
 
INSERT INTO t_sva VALUES ('1118090878');
INSERT INTO t_sva VALUES ('2345010477');
#+END_SRC

1118090878 is Austrian social security number, 09 = day of month, 08 = month, 78 = year, 1118 = a sequential number,
so that 1118090878 is actually after 2345010477.

how to implement this strange sort, we need our own handcrafted
indexing strategy using PostgreSQL's operator class.

** how it works
#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION normalize_si(text)
 
RETURNS text AS $$
 
        BEGIN
 
        RETURN substring($1, 9, 2) ||
 
                substring($1, 7, 2) || substring($1, 5, 2) || substring($1, 1, 4);
 
        END; $$
 
LANGUAGE 'plpgsql' IMMUTABLE;

SELECT normalize_si('1118090878');
 
normalize_si
 
--------------
 
7808091118
 
(1 row)

CREATE OR REPLACE FUNCTION si_lt(text, text)
 
        RETURNS boolean AS
 
$$
 
        BEGIN
 
                RETURN normalize_si($1) < normalize_si($2);
 
        END;
 
$$ LANGUAGE 'plpgsql' IMMUTABLE;
 
-- lower equals
 
CREATE OR REPLACE FUNCTION si_le(text, text)
 
        RETURNS boolean AS
 
$$
 
        BEGIN
 
                RETURN normalize_si($1) <= normalize_si($2);
 
        END;
 
$$ LANGUAGE 'plpgsql' IMMUTABLE;
 
-- greater equal
 
CREATE OR REPLACE FUNCTION si_ge(text, text)
 
RETURNS boolean AS
 
$$
 
BEGIN
 
RETURN normalize_si($1) >= normalize_si($2);
 
END;
 
$$ LANGUAGE 'plpgsql' IMMUTABLE;
 
-- greater
 
CREATE OR REPLACE FUNCTION si_gt(text, text)
 
RETURNS boolean AS
 
$$
 
BEGIN
 
RETURN normalize_si($1) > normalize_si($2);
 
END;
 
$$ LANGUAGE 'plpgsql' IMMUTABLE;


#+END_SRC

in PostgreSQL every operator is simply based on a stored procedure.

#+BEGIN_SRC sql
-- define operators
 
CREATE OPERATOR <# ( PROCEDURE=si_lt,
 
                        LEFTARG=text,
 
                        RIGHTARG=text);
 
CREATE OPERATOR <=# ( PROCEDURE=si_le,
 
                        LEFTARG=text,
 
                        RIGHTARG=text);
 
CREATE OPERATOR >=# ( PROCEDURE=si_ge,
 
                        LEFTARG=text,
 
                        RIGHTARG=text);
 
CREATE OPERATOR ># ( PROCEDURE=si_gt,
 
                        LEFTARG=text,
 
                        RIGHTARG=text);

tuplesort=# select * from t_sva order by sva  using >;
    sva     
------------
 2345010477
 1118090878
(2 rows)

tuplesort=# select * from t_sva order by sva  using >#;
    sva     
------------
 1118090878
 2345010477
(2 rows)
#+END_SRC

If you want to crate an operator you must tell PostgreSQL which
function to call.

** support functions
Before an index shows to handle a new strategy we have to define some
support functions.

#+BEGIN_SRC sql
CREATE OR REPLACE FUNCTION si_same(text, text)
 
        RETURNS int AS
 
$$
 
        BEGIN
 
                -- ugly code for clarity
 
                IF      normalize_si($1) < normalize_si($2)
 
                THEN
 
                        RETURN -1;
 
                ELSIF   normalize_si($1) > normalize_si($2)
 
                THEN
 
                        RETURN +1;
 
                ELSE
 
                        RETURN 0;
 
                END IF;
 
        END;
 
$$ LANGUAGE 'plpgsql' IMMUTABLE;
#+END_SRC

** create the operator classes
#+BEGIN_SRC sql
CREATE OPERATOR CLASS sva_special_ops
 
FOR TYPE text USING btree
 
AS
 
OPERATOR        1       <#  ,
 
OPERATOR        2       <=# ,
 
OPERATOR        3       =  ,
 
OPERATOR        4       >=# ,
 
OPERATOR        5       >#  ,
 
FUNCTION        1       si_same(text, text)
 
;
#+END_SRC

we have to tell index, which operators to use when and which support
functions to use.

#+BEGIN_SRC sql
CREATE INDEX idx_special ON t_sva (sva sva_special_ops);

SET enable_seqscan TO off;              -- to make sure that this work with just
 
                                                           -- two rows
 
explain SELECT * FROM t_sva WHERE sva = '0000112276';
 
                                  QUERY PLAN                                  
 
-------------------------------------------------------------------------------
 
 Index Only Scan using idx_special on t_sva  (cost=0.13..8.14 rows=1 width=32)
 
   Index Cond: (sva = '0000112276'::text)
 
(2 rows)



#+END_SRC

** relative catalog info

tuplesort=# select * from pg_operator where oprnamespace=2200;

| oprname | oprnamespace | oprowner | oprkind | oprcanmerge | oprcanhash | oprleft | oprright | oprresult | oprcom | oprnegate | oprcode | oprrest | oprjoin |
|---------+--------------+----------+---------+-------------+------------+---------+----------+-----------+--------+-----------+---------+---------+---------|
| <#      |         2200 |       10 | b       | f           | f          |      25 |       25 |        16 |      0 |         0 | si_lt   | -       | -       |
| <=#     |         2200 |       10 | b       | f           | f          |      25 |       25 |        16 |      0 |         0 | si_lt   | -       | -       |
| >=#     |         2200 |       10 | b       | f           | f          |      25 |       25 |        16 |      0 |         0 | si_lt   | -       | -       |
| >#      |         2200 |       10 | b       | f           | f          |      25 |       25 |        16 |      0 |         0 | si_lt   | -       | -       |

(4 rows)

tuplesort=# select * from pg_opfamily where opfnamespace=2200;

| opfmethod | opfname         | opfnamespace | opfowner |
|-----------+-----------------+--------------+----------|
|       403 | sva_special_ops |         2200 |       10 | 
  
(1 row)

tuplesort=# select * from pg_opclass where opcnamespace=2200;

| opcmethod | opcname         | opcnamespace | opcowner | opcfamily | opcintype | opcdefault | opckeytype |
|-----------+-----------------+--------------+----------+-----------+-----------+------------+------------|
|       403 | sva_special_ops |         2200 |       10 |     41020 |        25 | f          |          0 | 
  
(1 row)

tuplesort=# select * from pg_opfamily where oid=41020;

| opfmethod | opfname         | opfnamespace | opfowner |
|-----------+-----------------+--------------+----------|
|       403 | sva_special_ops |         2200 |       10 | 
  
(1 row)
 

[fn:1] http://www.cybertec.at/operator-classes-explained/
 
** pg_class

the pg_class system table contains one row for each table defined in
your database.


* system cache management

Every catalog cache must have a corresponding unique index on the
system table that it caches.[catcache.h] The extend explanation of it
is that every index in system table (ex., pg_class) has a
corresponding catalog cache represented by "struct catcache", every
row of the table that containing such a index has a corresponding tuple (presented by struct CatCtup) 
,which is stored in a double linked list, which is a element of
catcache' variable length array (called cc_bucket). Which double
linked list in cc_bucket is determined by hash value generated from
the row's contents and table's name. 

#+BEGIN_SRC c
typedef struct catcache
{
	int			id;				/* cache identifier --- see syscache.h */
	struct catcache *cc_next;	/* link to next catcache */
	const char *cc_relname;		/* name of relation the tuples come from */
      ...

	TupleDesc	cc_tupdesc;		/* tuple descriptor (copied from oreldesc) */
      ...
	int			cc_nbuckets;	/* # of hash buckets in this cache */
	int			cc_nkeys;		/* # of keys (1..4) */
	int			cc_key[4];		/* AttrNumber of each key */
	PGFunction	cc_hashfunc[4]; /* hash function to use for each key */
	ScanKeyData cc_skey[4];		/* precomputed key info for heap scans */

      ...
	Dllist		cc_bucket[1];	/* hash buckets --- VARIABLE LENGTH ARRAY */
} CatCache;						/* VARIABLE LENGTH STRUCT */

#+END_SRC


syscache's type is catcache, which is a low-level catalog cache. Every
system catalog table (ie, pg_class) is one item of syscache, and each
one is first time initiated by cacheinfo, of course, syscache and
cacheinfo have the same amount of items.

#+BEGIN_SRC c
struct cachedesc
{
	Oid			reloid;			/* OID of the relation being cached */
	Oid			indoid;			/* OID of index relation for this cache */
	int			reloidattr;		/* attr number of rel OID reference, or 0 */
	int			nkeys;			/* # of keys needed for cache lookup */
	int			key[4];			/* attribute numbers of key attrs */
	int			nbuckets;		/* number of hash buckets for this cache */
};
#+END_SRC

cacheinfo's type is cachedesc which defines a single syscache and contains all system catalog tables' index information, and
takes pg_class for examples,  
#+BEGIN_SRC c
	{RelationRelationId,		/* RELNAMENSP */
		ClassNameNspIndexId,
		ObjectIdAttributeNumber,
		2,
		{
			Anum_pg_class_relname,
			Anum_pg_class_relnamespace,
			0,
			0
		},
		1024
	},
#+END_SRC

ClassNameNspIndexId is defined in indexing.h:

#+BEGIN_SRC c
DECLARE_UNIQUE_INDEX(pg_class_relname_nsp_index, 2663, on pg_class using btree(relname name_ops, relnamespace oid_ops));
#define ClassNameNspIndexId  2663
#+END_SRC

pg_class_relname_nsp_index is the table pg_class' index name, we can
verify it using command:

#+BEGIN_SRC sql
tuplesort=# \d pg_class;
      Table "pg_catalog.pg_class"
     Column     |   Type    | Modifiers 
----------------+-----------+-----------
 relname        | name      | not null
 relnamespace   | oid       | not null

...

Indexes:
    "pg_class_oid_index" UNIQUE, btree (oid)
    "pg_class_relname_nsp_index" UNIQUE, btree (relname, relnamespace)

#+END_SRC

* composite variable declaration

A composite variable is one that corresponds to a complete row in a particular table. It has
fields that correspond to each column in the table. We can declare and use composite variables
in our stored procedures, either as rowtype or record.

To declare a composite variable, we use the rowtype declaration syntax
as follows:

name table%rowtype;

The result of this declaration will be a variable that itself has fields, one for each column in
the table on which it is based. Consider the following:
contact customer%rowtype;

This will create a variable called contact with fields corresponding to columns in the customer
table. To use the fields, we use the syntax variable.field. Here is an
example code fragment:

#+BEGIN_SRC sql
DECLARE
contact customer%rowtype;
address text;
BEGIN
contact.zipcode := 'XY1 6ZZ';
contact.fname := NULL;
address := contact.addressline || contact.town;
...
END;
#+END_SRC


* catach cache for create a new user table

 when create a new user table:
#+BEGIN_SRC sql
create table Reserves (sid integer, bid integer,day date,rname char(25));
#+END_SRC

The user table's namespace oid is 2200, and corresponding name is
 "public", so the member of new talbe's corresponding relation(type: VarRange) has a value "public" from get\_namespace\_name():
  
 ProcessUtility() -> transformCreateStmt() -> get\_namespace\_name() 


In PostgreSQL, creating a new table will define a new class, new type
and new attributes, so that it will add new row in pg_class, pg_type
and pg_attribute finished by calling AddNewRelationType(),
AddNewRelationTuple(pg_class_desc,...) and AddNewAttributeTuples() in
heap_create_with_catalog(). At the same time, every system table has a
corresponding CatCache, so that calling get_relname_relid() and others to add a relative item in these
CatCache variable perspectively is necessary.

DefineRelation() -> heap\_create\_with\_catalog()

* data structure

VarRange, RangeTblEntry and RangeTblRef are used in parsing phase.

- VarRange
  
  RangeVar is used in From clauses and utility statements (such as
  create table ...).

#+BEGIN_SRC c
/*
 * RangeVar - range variable, used in FROM clauses
 *
 * Also used to represent table names in utility statements; there, the alias
 * field is not used, and inhOpt shows whether to apply the operation
 * recursively to child tables.  In some contexts it is also useful to carry
 * a TEMP table indication here.
 */

typedef struct RangeVar
{
	NodeTag		type;
	char	   *catalogname;	/* the catalog (database) name, or NULL */
	char	   *schemaname;		/* the schema name, or NULL */
	char	   *relname;		/* the relation/sequence name */
	InhOption	inhOpt;			/* expand rel by inheritance? recursively act
								 * on children? */
	bool		istemp;			/* is this a temp relation/sequence? */
	Alias	   *alias;			/* table alias & optional column aliases */
	int			location;		/* token location, or -1 if unknown */
} RangeVar;

#+END_SRC

- RangeTblRef 
- RangeTblEntry

- ScanKey
 A ScanKey represents the application of a comparison operator between
  a table or index column and a constant.

#+BEGIN_SRC c
typedef struct ScanKeyData
{
	int			sk_flags;		/* flags, see below */
	AttrNumber	sk_attno;		/* table or index column number */
	StrategyNumber sk_strategy; /* operator strategy number */
	Oid			sk_subtype;		/* strategy subtype */
	FmgrInfo	sk_func;		/* lookup info for function to call */
	Datum		sk_argument;	/* data to compare */
} ScanKeyData;

typedef ScanKeyData *ScanKey;

#+END_SRC

From ScanKeyData, sk_attno defines which column in a table or index,
sk_strategy indicates that we want to search the column's data >, >=,
=, < or <= sk_argument(in general, a constant), sk_func defines a
different function according to the different access
method Btree, Gist, Gin, or Hash included in pg_am, so that if
a specific AM is defined the corresponding function such as btgettuple
will be defined.

- IndexScanDescData

#+BEGIN_SRC s
typedef struct IndexScanDescData
{
	/* scan parameters */
	Relation	heapRelation;	/* heap relation descriptor, or NULL */
	Relation	indexRelation;	/* index relation descriptor */
	Snapshot	xs_snapshot;	/* snapshot to see */
	int			numberOfKeys;	/* number of scan keys */
	ScanKey		keyData;		/* array of scan key descriptors */

	/* signaling to index AM about killing index tuples */
	bool		kill_prior_tuple;		/* last-returned tuple is dead */
	bool		ignore_killed_tuples;	/* do not return killed entries */

	/* index access method's private state */
	void	   *opaque;			/* access-method-specific info */
      ...
}
#+END_SRC

heapRelation is a table, indexRelation is a index for a
specific column for the table, so that there are several different
indexRelations for one table. keyData is the original ScanKey, opaque
includes output ScanKey, and is corresponding to BTScanOpaque,
GinScanOpaque, and GistScanOpaque, HashScanOpaque.

- HeapScanDescData
If there is no index in a table, the search will use
HeapScanDescData. And HeapScanDescData includes many detailed info for
one talbe such as rs_nblocks.

#+BEGIN_SRC c
typedef struct HeapScanDescData
{
	/* scan parameters */
	Relation	rs_rd;			/* heap relation descriptor */
	Snapshot	rs_snapshot;	/* snapshot to see */
	int			rs_nkeys;		/* number of scan keys */
	ScanKey		rs_key;			/* array of scan key descriptors */
	bool		rs_bitmapscan;	/* true if this is really a bitmap scan */
	bool		rs_pageatatime; /* verify visibility page-at-a-time? */
	bool		rs_allow_strat; /* allow or disallow use of access strategy */
	bool		rs_allow_sync;	/* allow or disallow use of syncscan */

	/* state set up at initscan time */
	BlockNumber rs_nblocks;		/* number of blocks to scan */
	BlockNumber rs_startblock;	/* block # to start at */
	BufferAccessStrategy rs_strategy;	/* access strategy for reads */
	bool		rs_syncscan;	/* report location to syncscan logic? */

#+END_SRC



* _bt_preprocess_keys() -- Preprocess scan keys

 comments: One key purpose of this routine is to discover how many scan keys
 must be satisfied to continue the scan. It also attempts to
 eliminate redundant keys and detect contradictory keys.

 what are contradictory keys? 

 the following keys are contradictory keys:

 key = 1 && key > 1 

 the above two expressions do not exist in this function, they only
 indicate that it is contradict if there exist two keys for one column of a table, one key's
 operator is =, the other >. How can we determine this case in
 PostgreSQL? Key is represented by ScanKey variables, =/> is
 corressponding to operator strategy, which included in Scankey. If
 the above cases exist, there must be two ScanKey variables, and their
 sk_attno is the same vaule. In _bt_preprocess_keys(), The
 different ScanKeys with the same sk_attno will be first stored in a
 array xfrom[] in order of operator strategy definition BTLessStrategyNumber, BTLessEqualStrategyNumber,
 BTEqualStrategyNumber, BTGreaterEqualStrategyNumber,
 BTGreaterStrategyNumber, and then check whether they are contradict,
 or redundant. 
#+BEGIN_SRC c
	inkeys = scan->keyData;
      ...
	cur = &inkeys[0];
      ...
      memset(xform, 0, sizeof(xform));

	for (i = 0;; cur++, i++)
      {
        if (... cur->sk_attno != attno){ //assert the same column
             ...
	     /* Re-initialize for new attno */
	     attno = cur->sk_attno;
	     memset(xform, 0, sizeof(xform));
        }
        j = cur->sk_strategy - 1;
   	  if (xform[j] == NULL)
	  {
		/* nope, so remember this scankey */
		xform[j] = cur;
	 }

      }
#+END_SRC		

#+BEGIN_SRC c
#define BTLessStrategyNumber			1
#define BTLessEqualStrategyNumber		2
#define BTEqualStrategyNumber			3
#define BTGreaterEqualStrategyNumber	4
#define BTGreaterStrategyNumber			5

#define BTMaxStrategyNumber				5
#+END_SRC

* some useful calling path
- btgettuple()->_bt_first()
- btbeginscan()->RelationGetIndexScan()->index_rescan()->FunctionCall2()->btgettuple()

- DefineRelation(CreateStmt *stmt, char relkind)->
  heap_create_with_catalog(relname,...)->get_relname_relid(const char
  *relname, Oid relnamespace)->
GetSysCacheOid(RELNAMENSP, PointerGetDatum(relname), ObjectIdGetDatum(relnamespace),
						  0, 0)
						  ->SearchSysCache(cacheId,
						  key1, key2, key3,
						  key4) ->
						  SearchCatCache(SysCache[cacheId],
						  key1, key2, key3,
						  key4) ->
						  systable_beginscan(relation,...) ->

* simple path for one simple query
The whole course is mainy finished in exec_simple_query(const char
*query_string), 

1. produces parse tree list through:
#+BEGIN_SRC c
   parsetree_list = pg_parse_query(query_string);
#+END_SRC,

2. travels the whole list:
#+BEGIN_SRC c
foreach(parsetree_item, parsetree_list){
   Node   *parsetree = (Node *) lfirst(parsetree_item);
}
#+END_SRC

3. for every item, experiences analyze, rewrite and getting plan tree
#+BEGIN_SRC c
querytree_list = pg_analyze_and_rewrite(parsetree, query_string,
												NULL, 0);
plantree_list = pg_plan_queries(querytree_list, 0, NULL);
#+END_SRC

4.execute plan tree
#+BEGIN_SRC c
portal = CreatePortal("", true, true);
PortalDefineQuery(portal,
				  NULL,
				  query_string,
				  commandTag,
				  plantree_list,
				  NULL);

PortalStart(portal, NULL, InvalidSnapshot);

(void) PortalRun(portal,
				 FETCH_ALL,
				 isTopLevel,
				 receiver,
				 receiver,
				 completionTag);
#+END_SRC







